# Experiment Queue ‚Äî Adversarial Negative Mining for Matrix Inversion

## Research Question
**Original**: Does adversarial negative mining improve performance on the matrix inversion task compared to baseline diffusion training and random negative mining?

**Updated (After Phase 0 Results)**: Why does adversarial negative mining underperform baseline and random mining on matrix inversion? Can it be rescued via hyperparameter tuning or training stability improvements?

## Hypotheses Tested (Phase 0 - COMPLETED)
1. **H1 (Baseline)**: Standard diffusion training without adversarial negatives achieves baseline performance ‚úì CONFIRMED (val_mse = 0.0096761)
2. **H2 (Random negatives)**: Random negative mining provides marginal improvement over baseline ‚úì NEUTRAL (val_mse = 0.00968396, +0.08% vs baseline - within noise)
3. **H3 (Adversarial negatives)**: Gradient-based hard negative mining significantly improves matrix inversion accuracy ‚úó REJECTED (val_mse = 0.00982675, +1.56% WORSE than baseline)

## New Hypotheses to Investigate
1. **H4 (Pathological conditioning)**: Adversarial mining pushes toward ill-conditioned matrices, learning "anti-inversion" patterns
2. **H5 (False negatives)**: Adversarial negatives collapse to narrow region near positives, losing diversity
3. **H6 (Hyperparameter sensitivity)**: Current adversarial config (opt_steps=2, noise_scale=3.0) is suboptimal; better tuning can rescue performance
4. **H7 (Training instability)**: Lack of LR decay, gradient clipping, and EMA hurts all strategies, especially adversarial

## Evaluation Metrics
- **Primary**: MSE (mean squared error) between predicted and true inverse matrices
- **Secondary**: Per-element accuracy, convergence speed (steps to threshold), energy landscape quality

---

## URGENT - CRITICAL BUG FIX REQUIRED

### IRED-CD Experiments - ALL RUNNING JOBS INVALID (Issue 12)
**Status**: ‚ö†Ô∏è CRITICAL - All 40 running experiments testing BROKEN code
**Discovery**: 2026-02-17T01:30:00Z
**Root Cause**: `mining_config` dictionary missing 12 of 15 required parameters
**Impact**: ALL CD features disabled across all experiments (q202, q203, q204)
**Fix**: Committed in bfbc5a0 (expanded mining_config to pass all 15 parameters)

**Current Running Jobs (ALL INVALID)**:
- q201_baseline (job 60619264): 10 seeds, git_sha=d2b8bc4 (broken)
- q202_cd_langevin (job 60619276): 10 seeds, git_sha=d2b8bc4 (broken)
- q203_cd_replay (job 60619287): 10 seeds, git_sha=d2b8bc4 (broken)
- q204_cd_full (job 60619298): 10 seeds, git_sha=d2b8bc4 (broken)

**Progress Before Discovery**: ~18% complete (7-8 of 40 seeds completed)
**Wasted GPU Time**: ~11 GPU-hours so far

**Required Actions**:
1. ‚úì **Fix committed** (bfbc5a0): Expanded mining_config to pass all 15 parameters
2. **CANCEL** all 4 running jobs (60619264, 60619276, 60619287, 60619298)
3. **RESUBMIT** all 4 experiments with git_sha=bfbc5a0 (fixed code)
4. **EXPECT** dramatically different results:
   - q202: CD loss + Langevin will actually activate
   - q203: + Replay buffer will actually work
   - q204: + Residual filtering + energy scheduling will activate
   - Previous identical MSE results (0.00972367, 0.00976373) were due to all CD features being disabled

**Compute Requirements (Re-run)**:
- Total: 40 experiments √ó 1.5h = 60 GPU-hours
- Wall-clock: ~4-6h (with array throttling %2 and 4 jobs in parallel)
- Partition strategy: Distribute across gpu_test and gpu to avoid QOS limits

**Expected Outcomes After Fix**:
- q201_baseline: Should be unchanged (only missing langevin_sigma_multiplier, minor)
- q202_cd_langevin: Should differ significantly from baseline (CD loss + Langevin active)
- q203_cd_replay: Should differ from q202 (replay buffer active)
- q204_cd_full: Should be best performer (all features active)

**Next Steps**:
```bash
# 1. Cancel all running jobs
scripts/cluster/cancel.sh 60619264 60619276 60619287 60619298

# 2. Verify fix is in current HEAD
git log -1 --oneline  # Should show bfbc5a0

# 3. Resubmit with fixed code
GIT_SHA=bfbc5a0 scripts/cluster/submit.sh projects/ired q201_baseline
GIT_SHA=bfbc5a0 scripts/cluster/submit.sh projects/ired q202_cd_langevin
GIT_SHA=bfbc5a0 scripts/cluster/submit.sh projects/ired q203_cd_replay
GIT_SHA=bfbc5a0 scripts/cluster/submit.sh projects/ired q204_cd_full
```

**Documentation**:
- See Issue 12 in debugging.md for complete technical details
- See commit bfbc5a0 for fix details and parameter mapping

---

## READY

### Phase 1: Validate Results (Multi-Seed Replication)

**INFRASTRUCTURE STATUS**: ‚úì COMPLETE (2026-01-21T18:30:00Z)
- Seed support added to experiments/matrix_inversion_mining.py
- Config files created for all three strategies
- SLURM array job scripts created with --array=0-9
- Ready for submission via /dispatch or manual sbatch

#### Q-101: Multi-seed baseline validation (10 seeds)
- **Config**: configs/q101_multiseed_baseline.json
- **SLURM Script**: slurm/jobs/q101_multiseed.sbatch
- **Strategy**: mining_strategy='none' (baseline)
- **Seeds**: 0-9 (10 independent runs via SLURM array)
- **Hyperparameters**: rank=20, diffusion_steps=10, batch=2048, train_steps=100K, lr=1e-4
- **Output**: results/ds_inverse/q101_seed{0-9}/
- **Purpose**: Establish confidence intervals for baseline performance
- **Expected Runtime**: ~1.5h per seed, 15 GPU-hours total
- **Wall-Clock Time**: ~1.5h if all 10 array tasks get resources simultaneously
- **Deliverable**: Mean ¬± std for train_mse and val_mse
- **Submission Command**:
  ```bash
  cd /Users/mkrasnow/Desktop/research-repo
  GIT_SHA=$(git rev-parse HEAD) scripts/cluster/submit.sh projects/ired q101_multiseed
  ```

#### Q-102: Multi-seed random mining validation (10 seeds)
- **Config**: configs/q102_multiseed_random.json
- **SLURM Script**: slurm/jobs/q102_multiseed.sbatch
- **Strategy**: mining_strategy='random'
- **Seeds**: 0-9 (10 independent runs via SLURM array)
- **Hyperparameters**: rank=20, diffusion_steps=10, batch=2048, train_steps=100K, lr=1e-4
- **Output**: results/ds_inverse/q102_seed{0-9}/
- **Purpose**: Establish confidence intervals for random mining
- **Expected Runtime**: ~1.5h per seed, 15 GPU-hours total
- **Wall-Clock Time**: ~1.5h if all 10 array tasks get resources simultaneously
- **Deliverable**: Mean ¬± std for train_mse and val_mse, rank consistency vs baseline
- **Submission Command**:
  ```bash
  cd /Users/mkrasnow/Desktop/research-repo
  GIT_SHA=$(git rev-parse HEAD) scripts/cluster/submit.sh projects/ired q102_multiseed
  ```

#### Q-103: Multi-seed adversarial mining validation (10 seeds)
- **Config**: configs/q103_multiseed_adversarial.json
- **SLURM Script**: slurm/jobs/q103_multiseed.sbatch
- **Strategy**: mining_strategy='adversarial'
- **Seeds**: 0-9 (10 independent runs via SLURM array)
- **Hyperparameters**: rank=20, diffusion_steps=10, batch=2048, train_steps=100K, lr=1e-4, mining_opt_steps=2, mining_noise_scale=3.0
- **Output**: results/ds_inverse/q103_seed{0-9}/
- **Purpose**: Establish confidence intervals for adversarial mining
- **Expected Runtime**: ~1.5h per seed, 15 GPU-hours total
- **Wall-Clock Time**: ~1.5h if all 10 array tasks get resources simultaneously
- **Deliverable**: Mean ¬± std for train_mse and val_mse, rank consistency
- **Submission Command**:
  ```bash
  cd /Users/mkrasnow/Desktop/research-repo
  GIT_SHA=$(git rev-parse HEAD) scripts/cluster/submit.sh projects/ired q103_multiseed
  ```

**TOTAL COMPUTE REQUIREMENTS FOR PHASE 1**:
- Total GPU-hours: 45 (30 jobs √ó 1.5h each)
- Wall-clock time (parallel): ~1.5h (if all 30 array tasks get resources)
- Wall-clock time (sequential): ~45h (worst case)
- Realistic estimate: ~3-6h (depends on cluster load and SLURM QOS limits)

#### Q-104: Learning curve analysis with frequent checkpointing
- **Config**: configs/q104_learning_curves.json
- **Strategy**: All three strategies (baseline, random, adversarial)
- **Checkpointing**: Save checkpoint every 5K steps (20 checkpoints total)
- **Purpose**: Compare "best checkpoint" vs "final checkpoint", detect training instability
- **Expected Runtime**: ~2h per strategy, 6h total
- **Deliverable**: Train/val MSE curves, identify when adversarial diverges

### Phase 2: Diagnose Why Adversarial Mining Fails

#### Q-201: Matrix conditioning analysis
- **Config**: configs/q201_conditioning_analysis.json
- **Purpose**: Determine if adversarial negatives are degenerate (near-singular matrices)
- **Metrics to track**:
  - Distribution of det(A) (or log|det|) for positive vs adversarial negatives
  - Distribution of cond(A) (condition number)
  - Distribution of smallest singular value œÉ_min
- **Expected Runtime**: ~2h
- **Hypothesis**: Adversarial mining pushes A toward ill-conditioned matrices, learning "anti-inversion noise"
- **Deliverable**: Statistical comparison of matrix properties (pos vs neg samples)

#### Q-202: Energy gap and hardness profiling
- **Config**: configs/q202_energy_profiling.json
- **Purpose**: Track energy landscape dynamics during adversarial mining
- **Metrics to track**:
  - E(pos) vs E(neg) gap over training
  - Frequency of false negatives (negatives too close to positives)
  - Gradient norms during mining steps
  - Diversity of generated negatives
- **Expected Runtime**: ~2h
- **Hypothesis**: Adversarial negatives collapse into narrow region near positives, losing diversity
- **Deliverable**: Energy gap plots, gradient norm statistics

### Phase 3: Fix Adversarial Mining (Hyperparameter Sweeps)

#### Q-301: Mining optimization steps sweep
- **Config**: configs/q301_opt_steps_sweep.json
- **Variants**: mining_opt_steps = [1, 3, 5, 10, 20]
- **Purpose**: Find optimal hardness level for adversarial negatives
- **Expected Runtime**: ~1.5h per variant, 7.5h total
- **Current config**: Unknown (need to check adversarial config)
- **Hypothesis**: Current opt_steps may be too high, making negatives pathologically hard
- **Deliverable**: Performance vs opt_steps curve

#### Q-302: Mining step size / ascent LR sweep
- **Config**: configs/q302_ascent_lr_sweep.json
- **Variants**: mining ascent LR = [0.01, 0.05, 0.1, 0.5, 1.0]
- **Purpose**: Control hardness by adjusting gradient ascent step size
- **Expected Runtime**: ~1.5h per variant, 7.5h total
- **Deliverable**: Performance vs ascent LR curve

#### Q-303: Mining noise scale sweep
- **Config**: configs/q303_noise_scale_sweep.json
- **Variants**: mining_noise_scale = [0.01, 0.1, 0.5, 1.0, 2.0]
- **Purpose**: Add controlled noise to prevent degenerate adversarial samples
- **Expected Runtime**: ~1.5h per variant, 7.5h total
- **Deliverable**: Performance vs noise scale curve

#### Q-304: Mixed strategy (random + adversarial)
- **Config**: configs/q304_mixed_strategy.json
- **Strategy**: 70% random negatives + 30% adversarial negatives
- **Purpose**: Test if mixing hardness levels improves over pure adversarial
- **Expected Runtime**: ~2h
- **Hypothesis**: Mixed approach balances diversity (random) with challenge (adversarial)
- **Deliverable**: Performance comparison vs pure strategies

### Phase 4: Training Stability Fixes

#### Q-401: Stabilized training (LR decay + grad clipping + EMA)
- **Config**: configs/q401_stabilized_training.json
- **Changes**:
  - Cosine LR decay starting at step 30K
  - Gradient clipping (max_norm=1.0)
  - EMA weights for evaluation (decay=0.995)
- **Strategy**: Apply to all three mining strategies
- **Purpose**: Fix late-stage training instability observed in validation run
- **Expected Runtime**: ~2h per strategy, 6h total
- **Deliverable**: Stable learning curves, improved final checkpoints

#### Q-402: Early stopping based on validation MSE
- **Config**: configs/q402_early_stopping.json
- **Changes**:
  - Track best validation MSE
  - Stop if no improvement for 10K steps
  - Save best checkpoint separately from final checkpoint
- **Strategy**: Apply to all three mining strategies
- **Purpose**: Prevent performance degradation in late training
- **Expected Runtime**: Variable (likely shorter than 100K steps)
- **Deliverable**: Best checkpoint selection, cleaner comparisons

---

## PROGRESS CHECKPOINTS

### IRED-CD Experiments - Partial Completion (2026-02-16T23:03:17Z)
- **Checkpoint Time**: 2026-02-16T23:03:17Z
- **Jobs**: q201 (60619264), q202 (60619276), q203 (60619287), q204 (60619298)
- **Status Summary**:
  - **q201_baseline**: 1 seed COMPLETED (seed 1: 1h53m), 1 seed TIMEOUT (seed 0: 2h), 2 seeds RUNNING (seeds 2-3: 35min), 6 seeds PENDING
  - **q202_cd_langevin**: 2 seeds COMPLETED (seeds 0-1: ~1h47m each), 2 seeds RUNNING (seeds 2-3: 33-52min), 6 seeds PENDING
  - **q203_cd_replay**: 2 seeds COMPLETED (seeds 0-1: ~1h47m each), 2 seeds RUNNING (seeds 2-3: 33min), 6 seeds PENDING
  - **q204_cd_full**: 2 seeds COMPLETED (seeds 0-1: ~1h47m each), 2 seeds RUNNING (seeds 2-3: 33min), 6 seeds PENDING
- **Total Progress**: 7 of 40 seeds completed (17.5%), 8 seeds running, 24 seeds pending, 1 timeout
- **Completed Results Available On Cluster**:
  - `/n/home03/mkrasnow/research-repo/projects/ired/results/ds_inverse/q201_seed1/results.json`
  - `/n/home03/mkrasnow/research-repo/projects/ired/results/ds_inverse/q202_seed{0,1}/results.json`
  - `/n/home03/mkrasnow/research-repo/projects/ired/results/ds_inverse/q203_seed{0,1}/results.json`
  - `/n/home03/mkrasnow/research-repo/projects/ired/results/ds_inverse/q204_seed{0,1}/results.json`
- **Concerns**:
  - q201 seed 0 TIMEOUT (2h runtime exceeds expected 1.5h): May indicate resource contention, training instability, or baseline strategy issue. Requires investigation after completion.
  - All other completed seeds finished in expected time range (1h47m-1h53m)
- **Estimated Completion**: ~4-6 hours remaining
  - Array throttle (%2) means 2 seeds run concurrently per experiment
  - Remaining: 4 batches of 2 seeds √ó ~1.75h = ~7h sequential time
  - With 4 experiments in parallel: ~7h wall-clock time (conservative estimate)
  - Optimistic: 4-5h if cluster resources available
- **Next Actions**:
  - Continue monitoring every 15 minutes
  - After all jobs complete, fetch results and analyze partial seed data
  - Investigate q201 seed 0 timeout (check logs for OOM, training divergence, or resource issues)
- **Next Poll**: 2026-02-16T23:18:17Z

---

## IN_PROGRESS

### Q-101: Multi-seed baseline validation (RUNNING)
- **Status**: SUBMITTED to SLURM
- **Job ID**: 56216344 (Array job: 10 tasks)
- **Run ID**: q101_20260121_124610
- **Submitted**: 2026-01-21T17:48:48Z
- **Git SHA**: 294cd74
- **Partition**: gpu
- **Array Spec**: 0-9%2 (10 tasks, throttled to 2 concurrent)
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM per task
- **Expected Runtime**: ~1.5h per seed
- **Expected Completion**: ~7.5h (5 sequential batches of 2 tasks)
- **Purpose**: Establish confidence intervals for baseline performance
- **Next Poll**: 2026-01-21T17:50:22Z (early poll in 60s)

### Q-102: Multi-seed random mining validation (RUNNING)
- **Status**: SUBMITTED to SLURM
- **Job ID**: 56216358 (Array job: 10 tasks)
- **Run ID**: q102_20260121_124613
- **Submitted**: 2026-01-21T17:48:48Z
- **Git SHA**: 294cd74
- **Partition**: gpu
- **Array Spec**: 0-9%2 (10 tasks, throttled to 2 concurrent)
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM per task
- **Expected Runtime**: ~1.5h per seed
- **Expected Completion**: ~7.5h (5 sequential batches of 2 tasks)
- **Purpose**: Establish confidence intervals for random mining
- **Next Poll**: 2026-01-21T17:50:22Z (early poll in 60s)

### Q-103: Multi-seed adversarial mining validation (RUNNING)
- **Status**: SUBMITTED to SLURM
- **Job ID**: 56216364 (Array job: 10 tasks)
- **Run ID**: q103_20260121_124900
- **Submitted**: 2026-01-21T17:48:48Z
- **Git SHA**: 294cd74
- **Partition**: gpu
- **Array Spec**: 0-9%2 (10 tasks, throttled to 2 concurrent)
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM per task
- **Expected Runtime**: ~1.5h per seed
- **Expected Completion**: ~7.5h (5 sequential batches of 2 tasks)
- **Purpose**: Establish confidence intervals for adversarial mining
- **Next Poll**: 2026-01-21T17:50:22Z (early poll in 60s)

**CRITICAL NOTES**:
- All 3 array jobs submitted successfully to gpu partition (gpu_test had QOSMaxSubmitJobPerUserLimit issues)
- Each array job throttled with %2 to run only 2 tasks concurrently (complies with resource constraints)
- Total: 30 tasks √ó 1.5h = 45 GPU-hours estimated
- Wall-clock time: ~7.5h (5 sequential batches of 2 tasks at 1.5h each)
- Early poll scheduled for 60s after submission to catch initialization errors

---

## DONE

### Q-003: Adversarial Negative Mining ‚úì COMPLETED
- **Status**: COMPLETED SUCCESSFULLY
- **Job ID**: 56194269
- **Run ID**: q003_20260121_143232
- **Submitted**: 2026-01-21T14:32:25Z
- **Started**: 2026-01-21T14:32:25Z
- **Completed**: 2026-01-21T16:51:32Z (approximately)
- **Runtime**: 1 hour 47 minutes 30 seconds (6450 seconds)
- **Git SHA**: 5437b3f (Fix PyHessian eigenvalues() API call)
- **Partition**: gpu_test
- **Node**: holygpu7c26105
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM
- **Results**:
  - Training MSE: 0.00980961
  - Validation MSE: 0.00982675
  - Iterations: 100,000 (completed all)
  - Configuration: 20√ó20 matrices, adversarial gradient-based negative mining
- **Milestone**: üéâ FINAL EXPERIMENT COMPLETED! Completes three-strategy comparison suite for matrix inversion with negative mining.
- **Key Finding**: Adversarial mining achieved validation MSE of 0.00982675, which is slightly HIGHER (worse) than baseline (0.0096761) and random mining (0.00968396). This suggests that gradient-based hard negatives may not provide the expected benefit for this task, or may require different hyperparameter tuning.

### Q-002: Random Negative Mining (RERUN) ‚úì COMPLETED
- **Status**: COMPLETED SUCCESSFULLY
- **Job ID**: 56185426
- **Run ID**: q002_20260121_124609
- **Submitted**: 2026-01-21T12:46:09Z
- **Started**: 2026-01-21T12:46:09Z
- **Completed**: 2026-01-21T14:26:36Z (approximately)
- **Runtime**: 1 hour 40 minutes 27 seconds (6027 seconds)
- **Git SHA**: 7770702 (includes result persistence fix)
- **Partition**: gpu_test
- **Node**: holygpu7c26105
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM
- **Results**:
  - Training MSE: 0.00968831
  - Validation MSE: 0.00968396
  - Iterations: 100,000 (completed all)
  - Configuration: 20√ó20 matrices, random negative mining
- **Milestone**: Random negative mining performed BEST among all three strategies with lowest validation MSE!
- **Note**: Second successful run with validated infrastructure. Rerun after first run 56017592 lost results due to /tmp cleanup.


### Q-001: Baseline (No Mining) ‚úì COMPLETED
- **Status**: COMPLETED SUCCESSFULLY
- **Job ID**: 56162645
- **Run ID**: q001_20260121_071917
- **Submitted**: 2026-01-21T07:19:17Z
- **Started**: 2026-01-21T07:19:17Z
- **Completed**: 2026-01-21T12:59:15Z (approximate)
- **Runtime**: 1 hour 40 minutes 18 seconds (6018 seconds)
- **Git SHA**: 7770702 (includes result persistence fix + dataset/diffusion fixes)
- **Partition**: gpu_test
- **Node**: holygpu7c26105
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM
- **Results**:
  - Training MSE: 0.0096721
  - Validation MSE: 0.0096761
  - Iterations: 100,000 (completed all)
  - Configuration: 20√ó20 matrices, no mining strategy (baseline)
- **Milestone**: First successful Q-001 run after multiple exit 120 failures! Validates:
  - All infrastructure fixes work correctly (result persistence, dataset API, diffusion code)
  - mining_strategy='none' baseline configuration executes correctly
  - Resource allocation (2 CPUs/16GB RAM/1 GPU) is appropriate
  - Automated git workflow functions properly
- **Root Cause Confirmed**: Previous Q-001 failures were due to OLD CODE (commit 75df3cf), not configuration issues
- **Next Steps**: Run Q-002 (random mining rerun) and Q-003 (adversarial mining) with commit 7770702

### Q-002: Random Negative Mining ‚úì COMPLETED (Results Lost, Will Rerun)
- **Status**: COMPLETED SUCCESSFULLY (but results not persisted - see Issue 9, now RESOLVED)
- **Job ID**: 56017592
- **Run ID**: q002_20260120_084822
- **Submitted**: 2026-01-20T08:48:22Z
- **Started**: 2026-01-20T08:48:25Z
- **Completed**: 2026-01-20T10:29:00Z (approximate)
- **Runtime**: 1 hour 40 minutes (6040 seconds)
- **Git SHA**: 75df3cf (before result persistence fix)
- **Partition**: gpu_test
- **Node**: holygpu7c26105
- **Resources**: 1 GPU, 2 CPUs, 16GB RAM
- **Results** (from SLURM logs only):
  - Training MSE: 0.0096382
  - Validation MSE: 0.00969288
  - Iterations: 100,000 (completed all)
  - Configuration: 20√ó20 matrices, random negative mining
- **Issue 9 Update**: Result persistence fix validated by ired-baseline job 56162316. Safe to rerun Q-002 with commit 7770702 to capture full results.
- **Milestone**: First successful full-scale experiment completion! Validates that:
  - 2 CPUs/16G RAM configuration works
  - Training code executes correctly for 100K iterations
  - Random mining strategy implemented correctly
- **Next Steps**: Rerun Q-002 after Q-001 succeeds, using commit 7770702 to capture full results with checkpoint files

### Q-004: Pilot Test (Debug Run) ‚úì COMPLETED
- **Status**: COMPLETED SUCCESSFULLY
- **Job ID**: 55214713
- **Run ID**: q004_20260113_234005
- **Submitted**: 2026-01-13T23:40:05Z
- **Started**: 2026-01-13T23:41:31Z
- **Completed**: 2026-01-13T23:42:37Z
- **Runtime**: 2 minutes 16 seconds (136s)
- **Git SHA**: 9a691f6 (automated git clone workflow)
- **Partition**: gpu_test
- **Workflow**: ‚úÖ Automated git clone to `/tmp/ired-job-55214713`
- **Modules**: python/3.10.13-fasrc01, cuda/11.8.0-fasrc01
- **Results**:
  - Training MSE: 0.0706
  - Validation MSE: 0.0688
  - Configuration: 10√ó10 matrices, 1000 steps, no mining
  - Output: results/ds_inverse/model_mlp_pilot
- **Milestone**: üéâ First successful completion with automated git workflow!
- **Validation**: Implementation works correctly, ready for full experiments

---

## FAILED

### Q-001: Baseline (No Mining) - MULTIPLE FAILURES
- **Status**: FAILED (consistent exit 120 failures, cause unknown)
- **Latest Job ID**: 56017590
- **Latest Run ID**: q001_20260120_084813
- **Failure Pattern**: Exit code 120:0 after 18-42 seconds
- **Key Anomaly**: Q-002 succeeds with identical configuration on same node
- **Attempts**:
  1. q001_20260120_084327 (job 56017462): Exit 120 after 42s, 2 CPUs/8G RAM (insufficient memory)
  2. q001_20260120_084813 (job 56017590): Exit 120 after 18s, 2 CPUs/16G RAM (same config as Q-002)
  3. Earlier attempts also failed with exit 120 or node failures
- **Investigation Status**: See Issue 8 in debugging.md
- **Next Steps**: Compare Q-001 and Q-002 config files to identify root cause

### Q-004: Pilot Test (Debug Run) - ATTEMPT 1
- **Status**: FAILED
- **Job ID**: 55131103
- **Run ID**: q004_20260113_185013
- **Submitted**: 2026-01-13T10:51:04Z
- **Failed**: 2026-01-13T22:36:38Z
- **Error**: `python: command not found`
- **Root cause**: Module load lines commented out in sbatch script
- **Fix applied**: Uncommented `module load python/3.9` and `module load cuda/11.7` in q004.sbatch

### Q-004: Pilot Test (Debug Run) - ATTEMPT 2
- **Status**: CANCELLED
- **Job ID**: 55208278
- **Run ID**: q004_20260113_223811
- **Submitted**: 2026-01-13T22:38:11Z
- **Cancelled**: 2026-01-13T22:55:00Z
- **Reason**: Redeployed with gpu_test partition for better queue priority (was submitted with old gpu partition)

### Q-004: Pilot Test (Debug Run) - ATTEMPT 3
- **Status**: FAILED
- **Job ID**: 55210815
- **Run ID**: q004_20260113_225500
- **Submitted**: 2026-01-13T22:55:00Z
- **Failed**: 2026-01-13T22:56:41Z
- **Error**: Module not found - `python/3.9` doesn't exist on cluster
- **Root cause**: Cluster uses versioned module names (e.g., `python/3.10.13-fasrc01`)
- **Fix applied**: Updated all sbatch scripts to use `python/3.10.13-fasrc01` and `cuda/11.8.0-fasrc01`

### Q-004: Pilot Test (Debug Run) - ATTEMPT 4
- **Status**: FAILED
- **Job ID**: 55211671
- **Run ID**: q004_20260113_225843
- **Submitted**: 2026-01-13T22:58:43Z
- **Failed**: 2026-01-13T23:00:29Z
- **Error**: File not found - `experiments/matrix_inversion_mining.py` doesn't exist on remote cluster
- **Root cause**: Git tracking issue - `projects/ired` is tracked as gitlink (submodule) not regular files
- **Required fix**: `git rm --cached projects/ired && git add projects/ired/ && git commit && git push`

### Q-004: Pilot Test (Debug Run) - ATTEMPT 5
- **Status**: FAILED
- **Job ID**: 55213584
- **Run ID**: q004_20260113_231120
- **Submitted**: 2026-01-13T23:11:20Z
- **Failed**: 2026-01-13T23:18:21Z
- **Error**: File not found - remote cluster repo hasn't pulled latest commit
- **Root cause**: Files committed and pushed (69c9fcf), but remote repo at `/n/home03/mkrasnow/research-repo` needs `git pull`
- **Required fix**: SSH to cluster and run `cd /n/home03/mkrasnow/research-repo && git pull`

---

## Future Extensions (After Initial Results)
- [ ] **Q-005**: Out-of-distribution test (ood=True, different regularization)
- [ ] **Q-006**: Larger matrices (rank=50) to test scalability
- [ ] **Q-007**: Different diffusion steps (20, 50, 100)
- [ ] **Q-008**: Ablation on opt_step parameters (1 step vs 5 steps)
- [ ] **Q-009**: Mixed strategy (adversarial + random negatives)
- [ ] **Q-010**: Energy landscape visualization and analysis
